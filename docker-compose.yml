services:
  prometheus:
    image: prom/prometheus:latest
    container_name: mon_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: mon_grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  dcgm_exporter:
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.8-3.1.5-ubuntu20.04
    container_name: mon_dcgm_exporter
    ports:
      - "9400:9400"
    cap_add:
      - SYS_ADMIN
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  node_exporter:
    image: prom/node-exporter:latest
    container_name: mon_node_exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: mon_cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    command:
      - '--logtostderr'
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  blackbox_exporter:
    image: prom/blackbox-exporter:latest
    container_name: mon_blackbox_exporter
    ports:
      - "9115:9115"
    volumes:
      - ./blackbox:/etc/blackbox_exporter
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  process_exporter:
    image: ncabatoff/process-exporter:latest
    container_name: mon_process_exporter
    ports:
      - "9256:9256"
    volumes:
      - /proc:/host/proc:ro
      - ./process-exporter:/etc/process-exporter
    command:
      - '--procfs=/host/proc'
      - '--config.path=/etc/process-exporter/config.yml'
    privileged: true
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  custom_metrics:
    image: prom/node-exporter:latest
    container_name: mon_custom_metrics
    ports:
      - "9101:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - custom_metrics_data:/etc/custom-metrics
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.textfile.directory=/etc/custom-metrics'
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped
    depends_on:
      - custom_metrics_runner

  custom_metrics_runner:
    build: ./custom-metrics
    container_name: mon_custom_metrics_runner
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - custom_metrics_data:/etc/custom-metrics
    networks:
      - mon_network
    labels:
      - "project=mon"
    restart: unless-stopped

  gpu_inference_exporter:
    build:
      context: ./gpu-inference-exporter
      dockerfile: Dockerfile
    container_name: mon_gpu_inference_exporter
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - EXPORTER_PORT=9201
      - SCRAPE_INTERVAL=10
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc:/host/proc:ro
    ports:
      - "9201:9201"
    networks:
      - mon_network
    labels:
      - "project=mon"
    privileged: true
    pid: host
    restart: unless-stopped


networks:
  mon_network:
    driver: bridge
    labels:
      - "project=mon"

volumes:
  prometheus_data:
    labels:
      - "project=mon"
  grafana_data:
    labels:
      - "project=mon"
  custom_metrics_data:
    labels:
      - "project=mon"